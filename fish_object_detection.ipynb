{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10295137,
          "sourceType": "datasetVersion",
          "datasetId": 6371851
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Gerekli kütüphanelerin kurulumu\n",
        "!pip install albumentations\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5 && pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "RJdisQafDiFk",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Önce Google Drive'ı bağlayalım\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTi_hrReKyhO",
        "outputId": "82606e78-4ede-42ce-bb29-2fed69918fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBCn-xF_Eoco",
        "outputId": "c65543a6-86f5-4b24-c13f-9faaab0764f9",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 25 14:15:37 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              12W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # True dönerse CUDA destekleniyor\n",
        "print(torch.cuda.device_count())  # Kullanılabilir GPU sayısını döner\n",
        "print(torch.cuda.get_device_name(0))  # GPU'nuzun adını döner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RfpClV0EKZJ",
        "outputId": "68b99be5-5d35-495a-dd96-6c96df83b37b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import albumentations as A\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Logging configuration\n",
        "# Bu kısım, loglama işleminin önce time sonra name sonra levelname ve sonra mesaj şeklinde yapılacağını belirtiyor.\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('training.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Config:  # Yaml dosyasını ayı bir dosya olarak koyamayacağımdan ötürü colabda bu şekilde bir class oluşturduk.\n",
        "    \"\"\"Configuration class for Colab environment\"\"\"\n",
        "    def __init__(self):\n",
        "        # Training parameters\n",
        "        self.BATCH_SIZE = 16\n",
        "        self.IMG_SIZE = 640\n",
        "        self.EPOCHS = 50\n",
        "        self.WORKERS = 2\n",
        "        self.LEARNING_RATE = 0.01\n",
        "\n",
        "        # Model parameters\n",
        "        self.ARCHITECTURE = \"yolov5m\"\n",
        "        self.NUM_CLASSES = 7\n",
        "        self.CONF_THRESHOLD = 0.25\n",
        "        self.CLASS_NAMES = ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
        "\n",
        "        # Paths - Colab specific\n",
        "        self.TRAIN_IMAGES = '/content/drive/MyDrive/train/images'\n",
        "        self.TRAIN_LABELS = '/content/drive/MyDrive/train/labels'\n",
        "        self.VAL_IMAGES = '/content/drive/MyDrive/valid/images'\n",
        "        self.VAL_LABELS = '/content/drive/MyDrive/valid/labels'\n",
        "        self.OUTPUT_DIR = '/content/drive/MyDrive/model_outputs'\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(self.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "    def validate_paths(self):\n",
        "        \"\"\"Validate that all required paths exist\"\"\"\n",
        "        paths = [self.TRAIN_IMAGES, self.TRAIN_LABELS,\n",
        "                self.VAL_IMAGES, self.VAL_LABELS]\n",
        "\n",
        "        for path in paths:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"Path not found: {path}\")\n",
        "\n",
        "        logger.info(\"All paths validated successfully\")\n",
        "\n",
        "\n",
        "\n",
        "class YOLODataset(Dataset):\n",
        "    \"\"\"Custom Dataset for YOLO training with coordinate validation\"\"\"\n",
        "    def __init__(self,\n",
        "                 images_dir: str,\n",
        "                 labels_dir: str,\n",
        "                 img_size: int = 640,\n",
        "                 transform: Optional[A.Compose] = None,\n",
        "                 is_training: bool = True):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.labels_dir = Path(labels_dir)\n",
        "        self.img_size = img_size\n",
        "        self.transform = transform\n",
        "        self.is_training = is_training\n",
        "\n",
        "        self.image_files = sorted([f for f in self.images_dir.glob('*')\n",
        "                                 if f.suffix.lower() in ('.jpg', '.jpeg', '.png')])\n",
        "        self.label_files = []\n",
        "\n",
        "        # Etiket dosyalarını kontrol et ve eşle\n",
        "        for img_file in self.image_files:\n",
        "            label_file = self.labels_dir / f\"{img_file.stem}.txt\"\n",
        "            if label_file.exists():\n",
        "                # Etiket dosyasının formatını kontrol et\n",
        "                try:\n",
        "                    self._validate_label_file(label_file)\n",
        "                    self.label_files.append(label_file)\n",
        "                except ValueError as e:\n",
        "                    logger.warning(f\"Skipping invalid label file {label_file}: {str(e)}\")\n",
        "                    continue\n",
        "            else:\n",
        "                logger.warning(f\"Missing label file for {img_file}\")\n",
        "                continue\n",
        "\n",
        "        self.image_files = [img for i, img in enumerate(self.image_files)\n",
        "                           if i < len(self.label_files)]\n",
        "\n",
        "        if not self.image_files:\n",
        "            raise FileNotFoundError(\"No valid image-label pairs found\")\n",
        "\n",
        "        logger.info(f\"Found {len(self.image_files)} valid image-label pairs\")\n",
        "\n",
        "    def _validate_label_file(self, label_path: Path) -> None:\n",
        "        \"\"\"YOLO format etiketlerini doğrula\"\"\"\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line_num, line in enumerate(f, 1):\n",
        "                try:\n",
        "                    values = [float(x) for x in line.strip().split()]\n",
        "                    if len(values) != 5:\n",
        "                        raise ValueError(f\"Each line must have 5 values, got {len(values)}\")\n",
        "\n",
        "                    class_id, x_center, y_center, width, height = values\n",
        "\n",
        "                    # class_id tam sayı olmalı\n",
        "                    if not float(class_id).is_integer():\n",
        "                        raise ValueError(f\"Class ID must be integer, got {class_id}\")\n",
        "\n",
        "                    # Koordinatlar 0-1 arasında olmalı\n",
        "                    for name, value in [(\"x_center\", x_center), (\"y_center\", y_center),\n",
        "                                      (\"width\", width), (\"height\", height)]:\n",
        "                        if not 0 <= value <= 1:\n",
        "                            raise ValueError(f\"{name} must be between 0 and 1, got {value}\")\n",
        "\n",
        "                except ValueError as e:\n",
        "                    raise ValueError(f\"Invalid format in {label_path} at line {line_num}: {str(e)}\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        try:\n",
        "            # Görüntüyü yükle\n",
        "            img_path = str(self.image_files[idx])\n",
        "            image = read_image(img_path).float() / 255.0\n",
        "\n",
        "            if image.shape[0] == 1:\n",
        "                image = image.repeat(3, 1, 1)\n",
        "\n",
        "            if image.shape[1] != self.img_size or image.shape[2] != self.img_size:\n",
        "                resize_transform = transforms.Resize((self.img_size, self.img_size))\n",
        "                image = resize_transform(image)\n",
        "\n",
        "            # Etiketleri yükle ve doğrula\n",
        "            label_path = str(self.label_files[idx])\n",
        "            boxes = []\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    values = [float(x) for x in line.strip().split()]\n",
        "                    if len(values) == 5:\n",
        "                        class_id = int(values[0])  # class_id'yi integer'a çevir\n",
        "                        # Koordinatları kontrol et ve düzelt\n",
        "                        x_center = np.clip(values[1], 0, 1)\n",
        "                        y_center = np.clip(values[2], 0, 1)\n",
        "                        width = np.clip(values[3], 0, 1)\n",
        "                        height = np.clip(values[4], 0, 1)\n",
        "                        boxes.append([class_id, x_center, y_center, width, height])\n",
        "\n",
        "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "            #print(boxes)\n",
        "\n",
        "            if self.transform and self.is_training:\n",
        "                transformed = self.transform(\n",
        "                    image=image.numpy().transpose(1, 2, 0),\n",
        "                    bboxes=boxes[:, 1:].numpy(),  # class_id'yi çıkar\n",
        "                    class_labels=boxes[:, 0].numpy().tolist()  # class_id'leri labels olarak kullan\n",
        "                )\n",
        "                image = torch.from_numpy(transformed['image'].transpose(2, 0, 1))\n",
        "                if transformed['bboxes'].size > 0:\n",
        "                    # Dönüştürülmüş bbox'ları ve class_id'leri birleştir\n",
        "                    new_boxes = np.column_stack([\n",
        "                        np.array(transformed['class_labels']).reshape(-1, 1),\n",
        "                        np.array(transformed['bboxes'])\n",
        "                    ])\n",
        "                    boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
        "                else:\n",
        "                    boxes = torch.zeros((0, 5))\n",
        "\n",
        "            return image, boxes\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading data at index {idx} from {img_path}: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class YOLOTrainer:\n",
        "    \"\"\"YOLO model trainer class\"\"\"\n",
        "    def __init__(self):\n",
        "        self.config = Config()\n",
        "        self.config.validate_paths()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.scaler = GradScaler()\n",
        "\n",
        "    def _get_transforms(self) -> A.Compose:\n",
        "        \"\"\"Get data augmentation transforms\"\"\"\n",
        "        return A.Compose([\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.2),\n",
        "            A.GaussNoise(p=0.2),\n",
        "        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Train the YOLO model\"\"\"\n",
        "        # Setup datasets\n",
        "        transform = self._get_transforms()\n",
        "        train_dataset = YOLODataset(\n",
        "            images_dir=self.config.TRAIN_IMAGES,\n",
        "            labels_dir=self.config.TRAIN_LABELS,\n",
        "            img_size=self.config.IMG_SIZE,\n",
        "            transform=transform,\n",
        "            is_training=True\n",
        "        )\n",
        "\n",
        "        val_dataset = YOLODataset(\n",
        "            images_dir=self.config.VAL_IMAGES,\n",
        "            labels_dir=self.config.VAL_LABELS,\n",
        "            img_size=self.config.IMG_SIZE,\n",
        "            transform=None,\n",
        "            is_training=False\n",
        "        )\n",
        "\n",
        "        # Setup dataloaders\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=self.config.WORKERS,\n",
        "            pin_memory=True,\n",
        "            collate_fn=self._collate_fn\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=self.config.WORKERS,\n",
        "            pin_memory=True,\n",
        "            collate_fn=self._collate_fn\n",
        "        )\n",
        "\n",
        "        # Initialize model\n",
        "        model = self._init_model()\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.config.EPOCHS):\n",
        "            train_metrics = self._train_epoch(model, train_loader, epoch)\n",
        "            val_metrics = self._validate_epoch(model, val_loader, epoch)\n",
        "\n",
        "            # Log metrics\n",
        "            logger.info(f\"Epoch {epoch}: {train_metrics} {val_metrics}\")\n",
        "\n",
        "            # Save checkpoint\n",
        "            self._save_checkpoint(model, epoch, val_metrics)\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(batch):\n",
        "        \"\"\"Custom collate function for DataLoader\"\"\"\n",
        "        images = torch.stack([item[0] for item in batch])\n",
        "        boxes = [item[1] for item in batch]\n",
        "        return images, boxes\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"Initialize YOLO model\"\"\"\n",
        "        model = torch.hub.load('ultralytics/yolov5',\n",
        "                             self.config.ARCHITECTURE,\n",
        "                             pretrained=True)\n",
        "        model.nc = self.config.NUM_CLASSES\n",
        "        model.to(self.device)\n",
        "        return model\n",
        "\n",
        "    def _train_epoch(self, model, dataloader, epoch: int) -> dict:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        model.train()\n",
        "        metrics = {\"train_loss\": 0.0}\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(dataloader):\n",
        "            images = images.to(self.device)\n",
        "            #targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "            targets = [{k[:,0]: k[:, 1:].to(self.device) for k in t.items} for t in targets]\n",
        "            print(targets)\n",
        "            # print(targets)\n",
        "            import time\n",
        "            time.sleep(999)\n",
        "\n",
        "\n",
        "            with autocast():\n",
        "                loss_dict = model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            self.scaler.scale(losses).backward()\n",
        "            self.scaler.step(model.optimizer)\n",
        "            self.scaler.update()\n",
        "            model.optimizer.zero_grad()\n",
        "\n",
        "            metrics[\"train_loss\"] += losses.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                logger.info(f\"Epoch {epoch} [{batch_idx}/{len(dataloader)}] Loss: {losses.item():.6f}\")\n",
        "\n",
        "        metrics[\"train_loss\"] /= len(dataloader)\n",
        "        return metrics\n",
        "\n",
        "    def _validate_epoch(self, model, dataloader, epoch: int) -> dict:\n",
        "        \"\"\"Validate for one epoch\"\"\"\n",
        "        model.eval()\n",
        "        metrics = {\"val_loss\": 0.0}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, targets in dataloader:\n",
        "                images = images.to(self.device)\n",
        "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                outputs = model(images)\n",
        "                # Calculate validation metrics\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _save_checkpoint(self, model, epoch: int, metrics: dict):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint_path = os.path.join(self.config.OUTPUT_DIR, f\"model_epoch_{epoch}.pt\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'metrics': metrics\n",
        "        }, checkpoint_path)\n",
        "\n",
        "        logger.info(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "class YOLOPredictor:\n",
        "    \"\"\"YOLO model predictor class\"\"\"\n",
        "    def __init__(self, weights_path: str):\n",
        "        self.config = Config()\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self._load_model(weights_path)\n",
        "\n",
        "    def _load_model(self, weights_path: str):\n",
        "        \"\"\"Load trained YOLO model\"\"\"\n",
        "        try:\n",
        "            model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_image(self, image_path: str) -> torch.Tensor:\n",
        "        \"\"\"Predict on a single image\"\"\"\n",
        "        try:\n",
        "            results = self.model(image_path)\n",
        "            results.pred[0] = results.pred[0][results.pred[0][:, 4] > self.config.CONF_THRESHOLD]\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error predicting image: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_video(self, video_path: str, output_path: str, batch_size: int = 32):\n",
        "        \"\"\"Predict on video with batch processing\"\"\"\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "            frames = []\n",
        "            frame_count = 0\n",
        "\n",
        "            try:\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "\n",
        "                    frames.append(frame)\n",
        "                    frame_count += 1\n",
        "\n",
        "                    if frame_count % batch_size == 0:\n",
        "                        batch_results = self.model(frames)\n",
        "\n",
        "                        for results in batch_results:\n",
        "                            annotated_frame = results.render()[0]\n",
        "                            out.write(annotated_frame)\n",
        "\n",
        "                        frames = []\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                if frames:\n",
        "                    batch_results = self.model(frames)\n",
        "                    for results in batch_results:\n",
        "                        annotated_frame = results.render()[0]\n",
        "                        out.write(annotated_frame)\n",
        "\n",
        "            finally:\n",
        "                cap.release()\n",
        "                out.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing video: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run training and prediction\"\"\"\n",
        "    try:\n",
        "        # Training\n",
        "        trainer = YOLOTrainer()\n",
        "        trainer.train()\n",
        "\n",
        "        # Prediction example\n",
        "        weights_path = os.path.join(trainer.config.OUTPUT_DIR, \"model_epoch_final.pt\")\n",
        "        predictor = YOLOPredictor(weights_path)\n",
        "\n",
        "        # Example predictions\n",
        "        image_path = \"../input/test_image.jpg\"\n",
        "        if os.path.exists(image_path):\n",
        "            results = predictor.predict_image(image_path)\n",
        "            logger.info(f\"Prediction results: {results}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ajsxcS1XDrjo",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model():\n",
        "    \"\"\"Test fonksiyonu - eğitilmiş modeli test seti üzerinde değerlendirir ve metrikleri gösterir\"\"\"\n",
        "    current_dir = os.getcwd()\n",
        "    test_image_dir = '../input/test/images'\n",
        "    test_label_dir = '../input/test/labels'\n",
        "    train_image_dir = '../input/train/images'  # Train yolu eklendi\n",
        "    val_image_dir = '../input/valid/images'    # Validation yolu eklendi\n",
        "\n",
        "    # Test verisi için YAML config\n",
        "    test_yaml = {\n",
        "        'path': current_dir,\n",
        "        'train': train_image_dir,     # Train yolu eklendi\n",
        "        'val': val_image_dir,         # Validation yolu eklendi\n",
        "        'test': test_image_dir,\n",
        "        'nc': 7,\n",
        "        'names': ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
        "    }\n",
        "\n",
        "    test_yaml_path = os.path.join(current_dir, 'test_data.yaml')\n",
        "    with open(test_yaml_path, 'w') as f:\n",
        "        yaml.dump(test_yaml, f)\n",
        "\n",
        "    # En iyi modeli test et\n",
        "    best_weights = os.path.join(current_dir, 'runs/train/yolov5_custom_model/weights/best.pt')\n",
        "\n",
        "    # val.run kullanarak test et\n",
        "    from yolov5 import val\n",
        "    results = val.run(\n",
        "        weights=best_weights,\n",
        "        data=test_yaml_path,\n",
        "        batch_size=16,\n",
        "        imgsz=640,\n",
        "        task='test',\n",
        "        verbose=True,\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        save_json=True,\n",
        "        project=os.path.join(current_dir, 'runs', 'test'),\n",
        "        name='yolov5_test_results'\n",
        "    )\n",
        "\n",
        "    # Sınıf bazlı metrikleri yazdır (eğer varsa)\n",
        "    if hasattr(results, 'ap_class_index'):\n",
        "        print(\"\\nSınıf Bazlı mAP@0.5:\")\n",
        "        class_names = ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
        "        for i, ap in enumerate(results.ap_class_index):\n",
        "            print(f\"{class_names[i]}: {ap:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "test_model()"
      ],
      "metadata": {
        "id": "RC4F-zwsOG3s",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}